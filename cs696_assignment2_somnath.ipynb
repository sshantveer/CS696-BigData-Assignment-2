{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Data CS696 - Assignment 2 - Somnath Shantveer (RedId - 823379096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "\n",
    "vehicle_data_file = 'assignment2Data/vehicles.csv'\n",
    "causes_of_death_file = 'assignment2Data/causes_of_death.csv'\n",
    "framingham_file = 'assignment2Data/framingham.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 1 : Fuel economy analysis\n",
    "- Analysing the fuel economy of the vehicles sold in US from year 2000 to 2019\n",
    "- Vehicle companies considered in analysis - GMC, Ford, Honda, Toyota, Chrysler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_data = pd.read_csv(vehicle_data_file, \n",
    "                           usecols=['make', 'model', 'year', 'comb08', 'atvType', 'fuelType1'])\n",
    "\n",
    "# Filter vehicle data based on year.\n",
    "vehicle_data = vehicle_data[vehicle_data.eval('year >= 2000 & year <= 2019')]\n",
    "\n",
    "#Filter vehicle data based on make.\n",
    "vehicle_make_list = ['Honda', 'Acura', \n",
    "                        'Toyota', 'Lexus', 'Scion', \n",
    "                        'GMC', 'Buick', 'Cadillac', 'Chevrolet', \n",
    "                        'Ford', 'Lincoln', \n",
    "                        'Chrysler', 'Dodge', 'Jeep', 'Ram']\n",
    "vehicle_data = vehicle_data[((vehicle_data['make']).isin(vehicle_make_list))]\n",
    "\n",
    "#Combine vehicle makes based on parent company. Replace 'make' with parent company name\n",
    "vehicle_data['make'] = vehicle_data['make'].replace(['GMC','Buick','Cadillac', 'Chevrolet'], 'General Motors').replace(['Lexus','Scion'], 'Toyota').replace(['Lincoln'], 'Ford').replace(['Dodge','Jeep', 'Ram'], 'Chrysler').replace(['Acura'], 'Honda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 \n",
    "For each company collect the MPG sold by each company in the years 2000-2019. Produce\n",
    "the box plots per company for the MPG over those years. How do the companies\n",
    "compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter vehicle data based on fuel type. Only Gasoline vehiclesHybrids are considered)\n",
    "vehicle_data_gasoline = vehicle_data[(vehicle_data['fuelType1'].str.contains('Gasoline'))]\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(data=vehicle_data_gasoline, x='make', y ='comb08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter vehicle data based on fuel type. Only Gasoline vehicles (Hybrids are not considered). No alternate fuel\n",
    "vehicle_data_gasoline_no_hybrid = vehicle_data_gasoline[vehicle_data_gasoline['atvType'].isnull()]\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.boxplot(data=vehicle_data_gasoline_no_hybrid, x='make', y ='comb08')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "Box plot for vehicles using gasoline (Hybrids are considered)\n",
    "- Honda vehicles has better fuel economy spread in the given years.\n",
    "- There are a lot of out liers from Toyota, which could be due to hybrid vehicles whose fuel economy(miles per gallon) is better.\n",
    "\n",
    "Box plot for vehicles using gasoline (Hybrids are not considered)\n",
    "- Honda vehicles has better fuel economy spread in the given years.\n",
    "- Overall fuel economy is less when we remove the hybrid vehicles from our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2\n",
    "Plot the yearly mean in the years 2000- 2019 with confidence interval of the mpg for each company. \n",
    "That is for each company compute the mean mpg over all vehicles sold by that company per year. \n",
    "What changes have there been in those years? How do the companies compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miles per gallon mean grouped by make per year. (Including hybrid vehicles)\n",
    "mpg_mean = vehicle_data_gasoline.groupby(['make', 'year'], as_index=False).mean().reset_index()\n",
    "\n",
    "sns.lmplot(x='year', y='comb08', data=mpg_mean, height=8, aspect=1.5, hue='make')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miles per gallon mean grouped by make per year. (Not including hybrid vehicles)\n",
    "mpg_mean_no_hybrid = vehicle_data_gasoline_no_hybrid.groupby(['make', 'year'], as_index=False).mean()\n",
    "mpg_mean_no_hybrid.reset_index\n",
    "\n",
    "sns.lmplot(x='year', y='comb08', data=mpg_mean_no_hybrid, height=8, aspect=1.5, hue='make')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "- The average fuel efficency has increased for all the makes during the year 2000 to 2019\n",
    "- Honda and Toyota vehicles have better mean fuel efficency during these years.\n",
    "- GM vehicles have less fuel efficency compared to other makes. Because of bigger vehicles!\n",
    "- There was a drop in Honda and Toyota mean values from year 2006 to 2013.\n",
    "- When comparing the fuel efficency mean of vehicles (with hybrids and without hybrids), we can see some\n",
    "makes of vehicle (ex: Toyota) having different growth line. It could be because of their efficient Prius!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3\n",
    "Plot the mpg for each company per year of their most fuel efficient vehicle each year. What\n",
    "changes have there been in those years? How do the companies compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpg grouped by make per year and get max value. (Including hybrid vehicles)\n",
    "mpg_max_yearly = vehicle_data_gasoline.groupby(['make', 'year'], as_index=False).max().reset_index()\n",
    "sns.lmplot(x='year', y='comb08', data=mpg_max_yearly, height=10, aspect=1.5, hue='make')\n",
    "\n",
    "# mpg grouped by make per year and get max value. (Not including hybrid vehicles)\n",
    "mpg_max_yearly = vehicle_data_gasoline_no_hybrid.groupby(['make', 'year'], as_index=False).max().reset_index()\n",
    "sns.lmplot(x='year', y='comb08', data=mpg_max_yearly, height=10, aspect=1.5, hue='make')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "- Efficient vehicle from each company has indication of improved mpg over the years except Honda.\n",
    "- Honda had a dip in mpg from 2006 to 2011 for their efficient vehicle.\n",
    "- Toyota had most efficient vehicle from 2006."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 2 - Diet and Death"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causes of death. \n",
    "Plot the death rate for each disease over time from the data set causes_of_death.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causes_of_death = pd.read_csv(causes_of_death_file)\n",
    "sns.lmplot(x='Year', y='Age Adjusted Death Rate', data=causes_of_death, height=8, aspect=1.5, hue='Cause')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes and the population. \n",
    "The data set in framingham.csv contains information from the Framingham Heart Study of 5,209 adults.\n",
    "First to check if the sample of people in the study is representative of the general population.\n",
    "We will use diabetes to test this. \n",
    "The CDC indicates that prevalence (percent) of diabetes was 0.93% at the time of the study. \n",
    "Our hypothesis:\n",
    "\n",
    "- Null Hypothesis: The probability that a participant within the Framingham Study has diabetes is\n",
    "equivalent to the prevalence of diagnosed diabetes within the population. (i.e., any difference\n",
    "is due to chance).\n",
    "- Alternative Hypothesis: The probability that a participant within the Framingham Study has diabetes\n",
    "is different than the prevalence of diagnosed diabetes within the population.\n",
    "In the framingham.csv file the column DIABETES contains 1 for people with diabetes and 0 for\n",
    "those without."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the percentage of people in the study that have diabetes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of people having diabetes in this study.\n",
    "farmingham_study_data = pd.read_csv(framingham_file)\n",
    "diabetes_pct = farmingham_study_data['DIABETES'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Percentage of people in the study that have diabetes = \", (diabetes_pct[1]*100).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compare this to the general population. Either a person is diagnosed as having\n",
    "diabetes or not. We can use the multinomial distribution to generate a sample of two values.\n",
    "Say we have an event that has .75 probability of occurring. Then the following will count\n",
    "the number of times the event does not occur and occur in a sample of 1000.\n",
    "\n",
    "two_value_probabilities = [0.25, 0.75]\n",
    "sample_size = 1000\n",
    "np.random.multinomial(sample_size, two_value_probabilities)\n",
    "\n",
    "Using this we can compute the number of people we would expect to have diabetes in a sample of 5,000, which we need to convert to a percentage. Now do this 200 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the percentage of the people with diabetes from the study, lets gnerate the sample to compare with general population.\n",
    "diabetes_probabilities = [diabetes_pct[0], diabetes_pct[1]]\n",
    "sample_size = 5000\n",
    "\n",
    "general_population_diabetes = pd.DataFrame(np.random.multinomial(sample_size, diabetes_probabilities, 200))\n",
    "general_population_diabetes.columns = ['non-diabetic', 'diabetic']\n",
    "\n",
    "# Convert to percentage\n",
    "general_population_diabetes = (100.*general_population_diabetes/sample_size).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Produce the histogram of the percent of people in your 200 samples with diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram of the diabetic percentage from the general population findings\n",
    "general_population_diabetes.hist(column='diabetic', bins=25, grid=False, figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compute the 95% confidence interval of the 200 values in 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns confidence interval of mean\n",
    "diabetic_confidence_interval = st.t.interval(0.95, len(general_population_diabetes[\"diabetic\"])-1, \n",
    "              loc=np.mean(general_population_diabetes[\"diabetic\"]), \n",
    "              scale=st.sem(general_population_diabetes[\"diabetic\"]))\n",
    "print(diabetic_confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Is the study representative of the general population? Why or why not?\n",
    "\n",
    "- Yes, study is representative of the general population.\n",
    "- The percentage of people having diabetes is 2.733%\n",
    "- When verified with general population, the 95% confidence interval is ~ (2.703 to 2.770)\n",
    "- The study diabetic percentage is within the 95% confidence range and hence represents the population (~95% accuracy). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Plot the cholesterol values\n",
    "In the file framingham.csv the column TOTCHOL gives the total cholesterol of each person in\n",
    "the study. The column ANYCHD indicates if the person has any heart disease.\n",
    "\n",
    "Plot the cholesterol values for the people with heart disease, for the people with out heart\n",
    "disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farmingham_study_data = pd.read_csv(framingham_file)\n",
    "\n",
    "# Ploting cholestrol data based on heart disease(ANYCHD).\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.boxplot(data=farmingham_study_data, x='ANYCHD', y ='TOTCHOL')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.violinplot(x='ANYCHD', y='TOTCHOL', data=farmingham_study_data, height=8)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.jointplot(x='ANYCHD', y='TOTCHOL', data=farmingham_study_data, height=8)\n",
    "\n",
    "sns.lmplot(y='TOTCHOL', x='AGE', data=farmingham_study_data, height=10, aspect=1, hue='ANYCHD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Compute the 95% confidence. \n",
    "Compute the 95% confidence interval of the cholesterol values for the people with heart disease, for the people with out heart disease.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create two groups, people with heart disease and without heart disease\n",
    "data_with_heart_disease = farmingham_study_data[farmingham_study_data['ANYCHD'] == 1]\n",
    "data_without_heart_disease = farmingham_study_data[farmingham_study_data['ANYCHD'] == 0]\n",
    "\n",
    "chol_confidence_interval_with_heart_disease = st.t.interval(0.95, len(data_with_heart_disease[\"TOTCHOL\"])-1, \n",
    "              loc=np.mean(data_with_heart_disease[\"TOTCHOL\"]), \n",
    "              scale=st.sem(data_with_heart_disease[\"TOTCHOL\"]))\n",
    "print('95% Confidence interval of the cholestrol for people with heart disease',\n",
    "      chol_confidence_interval_with_heart_disease)\n",
    "\n",
    "chol_confidence_interval_without_heart_disease = st.t.interval(0.95, len(data_without_heart_disease[\"TOTCHOL\"])-1, \n",
    "              loc=np.mean(data_without_heart_disease[\"TOTCHOL\"]), \n",
    "              scale=st.sem(data_without_heart_disease[\"TOTCHOL\"]))\n",
    "print('95% Confidence interval of the cholestrol for people with out heart disease', \n",
    "      chol_confidence_interval_without_heart_disease)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. What can we deduce about cholesterol values and heart disease?\n",
    "Answer: \n",
    "By looking at the graph and calculated confidence interval,\n",
    "- People with heart disease tend to have higher cholestrol level. \n",
    "  (or) People with high cholestrol level tend to get heart disease.\n",
    "- 95% of people having heart disease have cholestrol levels in the range - 246.5 to 252.4\n",
    "- 95% of people without heart disease have cholestrol levels in the range - 231.3 to 234.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
